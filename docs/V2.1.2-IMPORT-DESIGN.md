# V2.1.2 Import from Backup - Design & Architecture

**Version**: 2.1.2  
**Phase**: 3 - Design & Architecture  
**Created**: February 15, 2026  
**Status**: In Progress

---

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [Backend Design](#backend-design)
3. [Frontend Design](#frontend-design)
4. [Data Flow](#data-flow)
5. [Validation Pipeline](#validation-pipeline)
6. [ID Remapping Strategy](#id-remapping-strategy)
7. [Transaction Management](#transaction-management)
8. [Error Handling](#error-handling)
9. [Security Design](#security-design)
10. [Performance Considerations](#performance-considerations)

---

## Architecture Overview

### System Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ImportPage.jsx                                      ‚îÇ
‚îÇ  - File upload interface                             ‚îÇ
‚îÇ  - Mode selection                                    ‚îÇ
‚îÇ  - Progress tracking                                 ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  ImportModal.jsx                                     ‚îÇ
‚îÇ  - Replace mode confirmation                         ‚îÇ
‚îÇ  - Password verification                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚îÇ HTTP POST /api/import/backup
                   ‚îÇ (multipart/form-data)
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Backend (Express/Node.js)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Middleware Layer                                    ‚îÇ
‚îÇ  - Authentication (JWT)                              ‚îÇ
‚îÇ  - Rate Limiting (5/hour)                            ‚îÇ
‚îÇ  - File Upload (multer, 50MB max)                    ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  Route Layer                                         ‚îÇ
‚îÇ  - POST /api/import/backup                           ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  Controller Layer                                    ‚îÇ
‚îÇ  - importController.js                               ‚îÇ
‚îÇ    - importBackup()                                  ‚îÇ
‚îÇ    - validateBackupFile()                            ‚îÇ
‚îÇ    - validateBackupContent()                         ‚îÇ
‚îÇ    - detectDuplicates()                              ‚îÇ
‚îÇ    - executeImport()                                 ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  Service Layer                                       ‚îÇ
‚îÇ  - importValidator.js                                ‚îÇ
‚îÇ    - 5-layer validation                              ‚îÇ
‚îÇ  - importProcessor.js                                ‚îÇ
‚îÇ    - ID remapping                                    ‚îÇ
‚îÇ    - Reference updates                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚îÇ MongoDB Operations
                   ‚îÇ (with transactions)
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Database (MongoDB)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Collections:                                        ‚îÇ
‚îÇ  - users                                             ‚îÇ
‚îÇ  - recipes                                           ‚îÇ
‚îÇ  - collections                                       ‚îÇ
‚îÇ  - mealplans                                         ‚îÇ
‚îÇ  - shoppinglists                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Backend Design

### File Structure

```
backend/src/
‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îî‚îÄ‚îÄ importController.js         # Main import logic
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îî‚îÄ‚îÄ import.js                    # Import routes
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ importValidator.js           # Validation logic
‚îÇ   ‚îî‚îÄ‚îÄ importProcessor.js           # Import processing
‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îú‚îÄ‚îÄ auth.js                      # JWT authentication
‚îÇ   ‚îî‚îÄ‚îÄ uploadLimiter.js             # Rate limiting for imports
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ importErrors.js              # Custom error classes
```

### importController.js Design

```javascript
const multer = require('multer');
const User = require('../models/User');
const Recipe = require('../models/Recipe');
const Collection = require('../models/Collection');
const MealPlan = require('../models/MealPlan');
const ShoppingList = require('../models/ShoppingList');
const { 
  validateBackupFile, 
  validateBackupContent 
} = require('../services/importValidator');
const { 
  processRecipes, 
  processCollections, 
  processMealPlans, 
  processShoppingLists 
} = require('../services/importProcessor');
const { ImportError } = require('../utils/importErrors');

// Configure multer for file upload
const upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 50 * 1024 * 1024, // 50MB
  },
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'application/json' || file.originalname.endsWith('.json')) {
      cb(null, true);
    } else {
      cb(new ImportError('INVALID_FILE_TYPE', 'Must be .json file'), false);
    }
  },
});

/**
 * Main import handler
 * POST /api/import/backup
 */
exports.importBackup = [
  upload.single('file'),
  async (req, res) => {
    const session = await mongoose.startSession();
    
    try {
      // 1. Validate file exists
      if (!req.file) {
        throw new ImportError('NO_FILE', 'No file uploaded');
      }

      // 2. Parse JSON
      const backupData = JSON.parse(req.file.buffer.toString('utf8'));

      // 3. Validate file format and content
      await validateBackupFile(backupData);
      await validateBackupContent(backupData);

      // 4. Get mode and verify password if needed
      const mode = req.body.mode || 'merge';
      if (mode === 'replace') {
        const isValid = await User.comparePassword(
          req.user.id,
          req.body.password
        );
        if (!isValid) {
          throw new ImportError('INVALID_PASSWORD', 'Password is incorrect');
        }
      }

      // 5. Detect duplicates (merge mode only)
      let duplicates = null;
      if (mode === 'merge') {
        duplicates = await detectDuplicates(req.user.id, backupData);
      }

      // 6. Execute import in transaction
      const result = await executeImport(
        session,
        req.user.id,
        backupData,
        mode,
        duplicates
      );

      res.json({
        success: true,
        message: 'Import completed successfully',
        summary: result,
      });

    } catch (error) {
      if (error instanceof ImportError) {
        res.status(error.statusCode || 400).json({
          success: false,
          error: error.message,
          details: {
            code: error.code,
            message: error.details,
          },
        });
      } else if (error instanceof SyntaxError) {
        res.status(400).json({
          success: false,
          error: 'Invalid backup file',
          details: {
            code: 'INVALID_JSON',
            message: 'Backup file is not valid JSON',
          },
        });
      } else {
        console.error('Import error:', error);
        res.status(500).json({
          success: false,
          error: 'Import failed',
          details: {
            code: 'IMPORT_ERROR',
            message: 'An error occurred during import',
          },
        });
      }
    } finally {
      session.endSession();
    }
  },
];

/**
 * Detect duplicates in merge mode
 */
async function detectDuplicates(userId, backupData) {
  const duplicates = {
    recipes: new Set(),
    collections: new Set(),
    mealPlans: new Set(),
    shoppingLists: new Set(),
  };

  // Get existing user data
  const existingRecipes = await Recipe.find({ owner: userId });
  const existingCollections = await Collection.find({ owner: userId });
  const existingMealPlans = await MealPlan.find({ owner: userId });
  const existingShoppingLists = await ShoppingList.find({ owner: userId });

  // Check recipe duplicates (title + first 3 ingredients)
  backupData.data.recipes?.forEach((backupRecipe, index) => {
    const isDuplicate = existingRecipes.some((existing) => {
      if (existing.title.toLowerCase() !== backupRecipe.title.toLowerCase()) {
        return false;
      }
      
      // Compare first 3 ingredients
      const backupIngredients = backupRecipe.ingredients
        .slice(0, 3)
        .map((i) => i.name.toLowerCase())
        .sort();
      const existingIngredients = existing.ingredients
        .slice(0, 3)
        .map((i) => i.name.toLowerCase())
        .sort();
      
      return JSON.stringify(backupIngredients) === JSON.stringify(existingIngredients);
    });

    if (isDuplicate) {
      duplicates.recipes.add(index);
    }
  });

  // Check collection duplicates (name)
  backupData.data.collections?.forEach((backupCollection, index) => {
    const isDuplicate = existingCollections.some(
      (existing) => 
        existing.name.toLowerCase() === backupCollection.name.toLowerCase()
    );
    if (isDuplicate) {
      duplicates.collections.add(index);
    }
  });

  // Check meal plan duplicates (date + meal type)
  backupData.data.mealPlans?.forEach((backupMealPlan, index) => {
    const isDuplicate = existingMealPlans.some((existing) => {
      if (existing.date.toISOString().split('T')[0] !== backupMealPlan.date) {
        return false;
      }
      
      // Check if any meal types overlap
      const backupMealTypes = new Set(
        backupMealPlan.meals.map((m) => m.type)
      );
      const existingMealTypes = new Set(
        existing.meals.map((m) => m.type)
      );
      
      return [...backupMealTypes].some((type) => existingMealTypes.has(type));
    });

    if (isDuplicate) {
      duplicates.mealPlans.add(index);
    }
  });

  // Check shopping list duplicates (name)
  backupData.data.shoppingLists?.forEach((backupList, index) => {
    const isDuplicate = existingShoppingLists.some(
      (existing) => existing.name.toLowerCase() === backupList.name.toLowerCase()
    );
    if (isDuplicate) {
      duplicates.shoppingLists.add(index);
    }
  });

  return duplicates;
}

/**
 * Execute import transaction
 */
async function executeImport(session, userId, backupData, mode, duplicates) {
  const startTime = Date.now();
  const summary = {
    recipesImported: 0,
    collectionsImported: 0,
    mealPlansImported: 0,
    shoppingListsImported: 0,
    duplicatesSkipped: 0,
    mode,
    duration: 0,
  };

  try {
    await session.startTransaction();

    // Replace mode: Delete all existing data first
    if (mode === 'replace') {
      await Recipe.deleteMany({ owner: userId }, { session });
      await Collection.deleteMany({ owner: userId }, { session });
      await MealPlan.deleteMany({ owner: userId }, { session });
      await ShoppingList.deleteMany({ owner: userId }, { session });
    }

    // Process recipes first (base entities)
    const { imported: recipesImported, idMapping: recipeIdMapping } = 
      await processRecipes(
        userId,
        backupData.data.recipes || [],
        duplicates?.recipes,
        session
      );
    summary.recipesImported = recipesImported;

    // Process collections
    const { imported: collectionsImported } = await processCollections(
      userId,
      backupData.data.collections || [],
      recipeIdMapping,
      duplicates?.collections,
      session
    );
    summary.collectionsImported = collectionsImported;

    // Process meal plans
    const { imported: mealPlansImported } = await processMealPlans(
      userId,
      backupData.data.mealPlans || [],
      recipeIdMapping,
      duplicates?.mealPlans,
      session
    );
    summary.mealPlansImported = mealPlansImported;

    // Process shopping lists
    const { imported: shoppingListsImported } = await processShoppingLists(
      userId,
      backupData.data.shoppingLists || [],
      duplicates?.shoppingLists,
      session
    );
    summary.shoppingListsImported = shoppingListsImported;

    // Calculate duplicates skipped
    if (duplicates) {
      summary.duplicatesSkipped = 
        duplicates.recipes.size +
        duplicates.collections.size +
        duplicates.mealPlans.size +
        duplicates.shoppingLists.size;
    }

    await session.commitTransaction();

    summary.duration = Date.now() - startTime;
    return summary;

  } catch (error) {
    await session.abortTransaction();
    throw error;
  }
}
```

### importValidator.js Design

```javascript
const semver = require('semver');
const { ImportError } = require('../utils/importErrors');

/**
 * Layer 1 & 2: File format and schema validation
 */
exports.validateBackupFile = (data) => {
  // Required top-level fields
  const requiredFields = ['version', 'exportDate', 'user', 'data'];
  
  for (const field of requiredFields) {
    if (!data[field]) {
      throw new ImportError(
        'MISSING_FIELD',
        `Backup file is missing required field: ${field}`
      );
    }
  }

  // Validate version compatibility
  try {
    const backupVersion = semver.parse(data.version);
    if (!backupVersion || semver.lt(backupVersion, '2.0.0')) {
      throw new ImportError(
        'INCOMPATIBLE_VERSION',
        `Backup version ${data.version} not compatible. Requires 2.0.0+`
      );
    }
  } catch (error) {
    throw new ImportError(
      'INVALID_VERSION',
      `Invalid version format: ${data.version}`
    );
  }

  // Validate data object exists
  if (typeof data.data !== 'object' || data.data === null) {
    throw new ImportError(
      'INVALID_STRUCTURE',
      'Backup file data field must be an object'
    );
  }

  // Validate user object
  if (!data.user.username) {
    throw new ImportError(
      'MISSING_FIELD',
      'Backup file is missing user.username'
    );
  }
};

/**
 * Layer 3: Content validation
 */
exports.validateBackupContent = (data) => {
  const { recipes = [], collections = [], mealPlans = [], shoppingLists = [] } = data.data;

  // Validate recipes
  recipes.forEach((recipe, index) => {
    validateRecipe(recipe, index);
  });

  // Validate collections
  collections.forEach((collection, index) => {
    validateCollection(collection, index);
  });

  // Validate meal plans
  mealPlans.forEach((mealPlan, index) => {
    validateMealPlan(mealPlan, index);
  });

  // Validate shopping lists
  shoppingLists.forEach((list, index) => {
    validateShoppingList(list, index);
  });

  // Layer 4: Cross-reference validation
  validateReferences(data.data);

  // Layer 5: Security validation
  sanitizeData(data.data);
};

function validateRecipe(recipe, index) {
  const required = ['title', 'ingredients', 'instructions'];
  
  for (const field of required) {
    if (!recipe[field]) {
      throw new ImportError(
        'INVALID_RECIPE',
        `Recipe at index ${index} missing required field: ${field}`,
        { index, field }
      );
    }
  }

  // Validate title length
  if (recipe.title.length > 200) {
    throw new ImportError(
      'FIELD_TOO_LONG',
      `Recipe at index ${index} title exceeds 200 characters`,
      { index, field: 'title' }
    );
  }

  // Validate ingredients array
  if (!Array.isArray(recipe.ingredients) || recipe.ingredients.length === 0) {
    throw new ImportError(
      'INVALID_RECIPE',
      `Recipe at index ${index} must have at least one ingredient`,
      { index }
    );
  }

  // Validate each ingredient
  recipe.ingredients.forEach((ingredient, i) => {
    if (!ingredient.name || !ingredient.amount) {
      throw new ImportError(
        'INVALID_INGREDIENT',
        `Recipe '${recipe.title}' ingredient ${i} missing name or amount`,
        { index, ingredientIndex: i }
      );
    }
  });

  // Validate instructions array
  if (!Array.isArray(recipe.instructions) || recipe.instructions.length === 0) {
    throw new ImportError(
      'INVALID_RECIPE',
      `Recipe at index ${index} must have at least one instruction`,
      { index }
    );
  }

  // Validate each instruction
  recipe.instructions.forEach((instruction, i) => {
    if (!instruction.description) {
      throw new ImportError(
        'INVALID_INSTRUCTION',
        `Recipe '${recipe.title}' instruction ${i} missing description`,
        { index, instructionIndex: i }
      );
    }
  });
}

function validateCollection(collection, index) {
  if (!collection.name) {
    throw new ImportError(
      'INVALID_COLLECTION',
      `Collection at index ${index} missing name`,
      { index }
    );
  }

  if (!Array.isArray(collection.recipeIds)) {
    collection.recipeIds = [];
  }
}

function validateMealPlan(mealPlan, index) {
  if (!mealPlan.date) {
    throw new ImportError(
      'INVALID_MEAL_PLAN',
      `Meal plan at index ${index} missing date`,
      { index }
    );
  }

  if (!Array.isArray(mealPlan.meals)) {
    throw new ImportError(
      'INVALID_MEAL_PLAN',
      `Meal plan at index ${index} missing meals array`,
      { index }
    );
  }

  const validMealTypes = ['breakfast', 'lunch', 'dinner', 'snack'];
  mealPlan.meals.forEach((meal, i) => {
    if (!meal.type || !validMealTypes.includes(meal.type)) {
      throw new ImportError(
        'INVALID_MEAL',
        `Meal plan for ${mealPlan.date} meal ${i} has invalid type`,
        { index, mealIndex: i }
      );
    }
  });
}

function validateShoppingList(list, index) {
  if (!list.name) {
    throw new ImportError(
      'INVALID_SHOPPING_LIST',
      `Shopping list at index ${index} missing name`,
      { index }
    );
  }

  if (!Array.isArray(list.items)) {
    list.items = [];
  }
}

function validateReferences(data) {
  const recipeIds = new Set((data.recipes || []).map((r) => r._id));

  // Validate collection references
  (data.collections || []).forEach((collection) => {
    collection.recipeIds.forEach((recipeId) => {
      if (!recipeIds.has(recipeId)) {
        console.warn(
          `Collection '${collection.name}' references missing recipe: ${recipeId}`
        );
      }
    });
  });

  // Validate meal plan references
  (data.mealPlans || []).forEach((mealPlan) => {
    mealPlan.meals.forEach((meal) => {
      if (meal.recipes) {
        meal.recipes.forEach((recipe) => {
          if (!recipeIds.has(recipe.recipeId)) {
            console.warn(
              `Meal plan for ${mealPlan.date} references missing recipe: ${recipe.recipeId}`
            );
          }
        });
      }
    });
  });
}

function sanitizeData(data) {
  // Sanitize string fields to prevent XSS
  const sanitizeString = (str) => {
    if (typeof str !== 'string') return str;
    return str
      .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '')
      .replace(/javascript:/gi, '')
      .replace(/on\w+=/gi, '');
  };

  const sanitizeObject = (obj) => {
    if (typeof obj === 'string') {
      return sanitizeString(obj);
    }
    if (Array.isArray(obj)) {
      return obj.map(sanitizeObject);
    }
    if (typeof obj === 'object' && obj !== null) {
      const sanitized = {};
      for (const [key, value] of Object.entries(obj)) {
        sanitized[key] = sanitizeObject(value);
      }
      return sanitized;
    }
    return obj;
  };

  // Sanitize all data
  data.recipes = sanitizeObject(data.recipes || []);
  data.collections = sanitizeObject(data.collections || []);
  data.mealPlans = sanitizeObject(data.mealPlans || []);
  data.shoppingLists = sanitizeObject(data.shoppingLists || []);
}
```

### importProcessor.js Design

```javascript
const mongoose = require('mongoose');
const Recipe = require('../models/Recipe');
const Collection = require('../models/Collection');
const MealPlan = require('../models/MealPlan');
const ShoppingList = require('../models/ShoppingList');

/**
 * Process and import recipes
 */
exports.processRecipes = async (userId, recipes, duplicates, session) => {
  const idMapping = new Map();
  let imported = 0;

  for (let i = 0; i < recipes.length; i++) {
    // Skip if duplicate
    if (duplicates && duplicates.has(i)) {
      continue;
    }

    const backupRecipe = recipes[i];
    const oldId = backupRecipe._id;

    // Create new recipe document
    const newRecipe = new Recipe({
      owner: userId,
      title: backupRecipe.title,
      description: backupRecipe.description || '',
      ingredients: backupRecipe.ingredients,
      instructions: backupRecipe.instructions,
      prepTime: backupRecipe.prepTime,
      cookTime: backupRecipe.cookTime,
      servings: backupRecipe.servings,
      dishType: backupRecipe.dishType,
      cuisine: backupRecipe.cuisine,
      tags: backupRecipe.tags || [],
      rating: backupRecipe.rating,
      sourceUrl: backupRecipe.sourceUrl || '',
      visibility: backupRecipe.visibility || 'private',
    });

    await newRecipe.save({ session });

    // Map old ID to new ID
    idMapping.set(oldId, newRecipe._id.toString());
    imported++;
  }

  return { imported, idMapping };
};

/**
 * Process and import collections
 */
exports.processCollections = async (
  userId,
  collections,
  recipeIdMapping,
  duplicates,
  session
) => {
  let imported = 0;

  for (let i = 0; i < collections.length; i++) {
    // Skip if duplicate
    if (duplicates && duplicates.has(i)) {
      continue;
    }

    const backupCollection = collections[i];

    // Remap recipe IDs
    const remappedRecipeIds = backupCollection.recipeIds
      .map((oldId) => recipeIdMapping.get(oldId))
      .filter((id) => id !== undefined); // Remove missing references

    const newCollection = new Collection({
      owner: userId,
      name: backupCollection.name,
      description: backupCollection.description || '',
      recipeIds: remappedRecipeIds,
      recipeCount: remappedRecipeIds.length,
    });

    await newCollection.save({ session });
    imported++;
  }

  return { imported };
};

/**
 * Process and import meal plans
 */
exports.processMealPlans = async (
  userId,
  mealPlans,
  recipeIdMapping,
  duplicates,
  session
) => {
  let imported = 0;

  for (let i = 0; i < mealPlans.length; i++) {
    // Skip if duplicate
    if (duplicates && duplicates.has(i)) {
      continue;
    }

    const backupMealPlan = mealPlans[i];

    // Remap recipe references in meals
    const remappedMeals = backupMealPlan.meals.map((meal) => ({
      type: meal.type,
      recipes: (meal.recipes || [])
        .map((recipe) => {
          const newRecipeId = recipeIdMapping.get(recipe.recipeId);
          if (!newRecipeId) return null; // Skip missing references
          
          return {
            recipeId: newRecipeId,
            title: recipe.title,
            servings: recipe.servings,
          };
        })
        .filter((recipe) => recipe !== null),
    }));

    const newMealPlan = new MealPlan({
      owner: userId,
      date: new Date(backupMealPlan.date),
      meals: remappedMeals,
    });

    await newMealPlan.save({ session });
    imported++;
  }

  return { imported };
};

/**
 * Process and import shopping lists
 */
exports.processShoppingLists = async (
  userId,
  shoppingLists,
  duplicates,
  session
) => {
  let imported = 0;

  for (let i = 0; i < shoppingLists.length; i++) {
    // Skip if duplicate
    if (duplicates && duplicates.has(i)) {
      continue;
    }

    const backupList = shoppingLists[i];

    const newShoppingList = new ShoppingList({
      owner: userId,
      name: backupList.name,
      items: backupList.items,
      createdAt: backupList.createdAt ? new Date(backupList.createdAt) : new Date(),
    });

    await newShoppingList.save({ session });
    imported++;
  }

  return { imported };
};
```

### import.js Routes Design

```javascript
const express = require('express');
const router = express.Router();
const importController = require('../controllers/importController');
const auth = require('../middleware/auth');
const { createUploadLimiter } = require('../middleware/uploadLimiter');

// Rate limiter: 5 imports per hour
const uploadLimiter = createUploadLimiter({
  windowMs: 60 * 60 * 1000, // 1 hour
  max: 5, // 5 requests per hour
  message: {
    success: false,
    error: 'Too many import attempts',
    details: {
      code: 'RATE_LIMIT_EXCEEDED',
      message: 'Maximum 5 imports per hour. Try again later.',
    },
  },
});

// Import backup
router.post('/backup', auth, uploadLimiter, importController.importBackup);

module.exports = router;
```

---

## Frontend Design

### File Structure

```
frontend/src/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ ImportPage.jsx              # Main import interface
‚îÇ   ‚îî‚îÄ‚îÄ ImportModal.jsx             # Replace mode confirmation
‚îî‚îÄ‚îÄ services/
    ‚îî‚îÄ‚îÄ api.js                       # API methods (add import functions)
```

### ImportPage.jsx Design

```jsx
import React, { useState } from 'react';
import { useNavigate } from 'react-router-dom';
import { importAPI } from '../services/api';
import ImportModal from './ImportModal';

const ImportPage = () => {
  const navigate = useNavigate();
  const [selectedFile, setSelectedFile] = useState(null);
  const [mode, setMode] = useState('merge');
  const [isImporting, setIsImporting] = useState(false);
  const [progress, setProgress] = useState('');
  const [result, setResult] = useState(null);
  const [error, setError] = useState(null);
  const [showModal, setShowModal] = useState(false);

  const handleFileSelect = (event) => {
    const file = event.target.files[0];
    
    // Validate file
    if (file) {
      if (!file.name.endsWith('.json')) {
        setError('Must be .json file');
        return;
      }
      if (file.size > 50 * 1024 * 1024) {
        setError('File exceeds 50MB');
        return;
      }
      setSelectedFile(file);
      setError(null);
    }
  };

  const handleDrop = (event) => {
    event.preventDefault();
    const file = event.dataTransfer.files[0];
    if (file) {
      handleFileSelect({ target: { files: [file] } });
    }
  };

  const handleImport = () => {
    if (!selectedFile) {
      setError('Please select a file');
      return;
    }

    if (mode === 'replace') {
      setShowModal(true);
    } else {
      executeImport();
    }
  };

  const executeImport = async (password = null) => {
    setIsImporting(true);
    setProgress('Uploading file...');
    setError(null);
    setResult(null);

    try {
      const response = await importAPI.importBackup(
        selectedFile,
        mode,
        password
      );

      setResult(response.summary);
      setProgress('');
    } catch (err) {
      setError(err.response?.data?.details?.message || 'Import failed');
      setProgress('');
    } finally {
      setIsImporting(false);
      setShowModal(false);
    }
  };

  return (
    <div className="container mx-auto px-4 py-8 max-w-2xl">
      <h1 className="text-3xl font-bold mb-2">Import Backup</h1>
      <p className="text-gray-600 mb-8">
        Restore your recipes, collections, meal plans, and shopping lists from a backup file.
      </p>

      {/* File Upload */}
      <div className="mb-6">
        <label className="block text-sm font-semibold mb-2">
          Upload Backup File
        </label>
        <div
          className="border-2 border-dashed border-gray-300 rounded-lg p-8 text-center cursor-pointer hover:border-blue-500 transition"
          onDrop={handleDrop}
          onDragOver={(e) => e.preventDefault()}
          onClick={() => document.getElementById('file-input').click()}
        >
          {selectedFile ? (
            <div>
              <p className="text-green-600 font-medium">‚úì {selectedFile.name}</p>
              <p className="text-sm text-gray-500">
                {(selectedFile.size / 1024 / 1024).toFixed(2)} MB ‚Ä¢ Selected
              </p>
            </div>
          ) : (
            <div>
              <p className="text-gray-600">Drag & Drop or Click to Select</p>
              <p className="text-sm text-gray-500">üìÑ .json files only (max 50MB)</p>
            </div>
          )}
        </div>
        <input
          id="file-input"
          type="file"
          accept=".json"
          onChange={handleFileSelect}
          className="hidden"
        />
      </div>

      {/* Import Mode */}
      <div className="mb-6">
        <label className="block text-sm font-semibold mb-2">Import Mode</label>
        <div className="space-y-3">
          <label className="flex items-start cursor-pointer">
            <input
              type="radio"
              value="merge"
              checked={mode === 'merge'}
              onChange={(e) => setMode(e.target.value)}
              className="mt-1 mr-3"
            />
            <div>
              <p className="font-medium">Merge with existing data (recommended)</p>
              <p className="text-sm text-gray-600">
                Add items from backup without removing your current data. Duplicates will be skipped.
              </p>
            </div>
          </label>
          <label className="flex items-start cursor-pointer">
            <input
              type="radio"
              value="replace"
              checked={mode === 'replace'}
              onChange={(e) => setMode(e.target.value)}
              className="mt-1 mr-3"
            />
            <div>
              <p className="font-medium">Replace all existing data</p>
              <p className="text-sm text-orange-600">
                ‚ö†Ô∏è Delete all current data and restore only items from backup.
              </p>
            </div>
          </label>
        </div>
      </div>

      {/* Progress */}
      {isImporting && (
        <div className="mb-6 p-4 bg-blue-50 rounded-lg">
          <p className="text-blue-700">‚è≥ {progress}</p>
        </div>
      )}

      {/* Error */}
      {error && (
        <div className="mb-6 p-4 bg-red-50 rounded-lg">
          <p className="text-red-700">‚úó {error}</p>
        </div>
      )}

      {/* Success Result */}
      {result && (
        <div className="mb-6 p-4 bg-green-50 rounded-lg">
          <h3 className="font-bold text-green-700 mb-2">‚úì Import Complete!</h3>
          <p className="text-sm mb-2">Successfully imported your backup:</p>
          <ul className="text-sm space-y-1">
            <li>‚Ä¢ {result.recipesImported} recipes</li>
            <li>‚Ä¢ {result.collectionsImported} collections</li>
            <li>‚Ä¢ {result.mealPlansImported} meal plans</li>
            <li>‚Ä¢ {result.shoppingListsImported} shopping lists</li>
          </ul>
          {result.duplicatesSkipped > 0 && (
            <p className="text-sm mt-2">
              {result.duplicatesSkipped} duplicate items were skipped (merge mode)
            </p>
          )}
          <p className="text-sm text-gray-600 mt-2">
            Import completed in {(result.duration / 1000).toFixed(1)} seconds
          </p>
        </div>
      )}

      {/* Actions */}
      <div className="flex gap-3">
        <button
          onClick={() => navigate('/recipes')}
          className="px-4 py-2 border border-gray-300 rounded-lg hover:bg-gray-50"
        >
          Cancel
        </button>
        <button
          onClick={handleImport}
          disabled={!selectedFile || isImporting}
          className="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:bg-gray-300"
        >
          {isImporting ? 'Importing...' : 'Import Backup'}
        </button>
      </div>

      {/* Replace Mode Confirmation Modal */}
      {showModal && (
        <ImportModal
          onConfirm={executeImport}
          onCancel={() => setShowModal(false)}
        />
      )}
    </div>
  );
};

export default ImportPage;
```

### ImportModal.jsx Design

```jsx
import React, { useState } from 'react';

const ImportModal = ({ onConfirm, onCancel }) => {
  const [password, setPassword] = useState('');
  const [confirmed, setConfirmed] = useState(false);
  const [error, setError] = useState('');

  const handleConfirm = () => {
    if (!password) {
      setError('Password is required');
      return;
    }
    if (!confirmed) {
      setError('You must confirm you understand');
      return;
    }
    onConfirm(password);
  };

  return (
    <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
      <div className="bg-white rounded-lg p-6 max-w-md w-full mx-4">
        <h3 className="text-xl font-bold text-orange-600 mb-4">
          ‚ö†Ô∏è Replace All Data - Are You Sure?
        </h3>
        
        <p className="mb-4 font-medium">
          This action is PERMANENT and CANNOT be undone.
        </p>
        
        <p className="mb-2">All of your current data will be DELETED:</p>
        <ul className="mb-4 space-y-1 text-sm">
          <li>‚Ä¢ All your recipes</li>
          <li>‚Ä¢ All your collections</li>
          <li>‚Ä¢ All your meal plans</li>
          <li>‚Ä¢ All your shopping lists</li>
        </ul>
        
        <p className="mb-4">Only items from the backup file will remain.</p>
        
        <div className="mb-4">
          <label className="block text-sm font-medium mb-2">
            Enter your password to confirm:
          </label>
          <input
            type="password"
            value={password}
            onChange={(e) => {
              setPassword(e.target.value);
              setError('');
            }}
            className="w-full px-3 py-2 border border-gray-300 rounded-lg"
            placeholder="Password"
          />
        </div>
        
        <label className="flex items-start mb-4 cursor-pointer">
          <input
            type="checkbox"
            checked={confirmed}
            onChange={(e) => {
              setConfirmed(e.target.checked);
              setError('');
            }}
            className="mt-1 mr-2"
          />
          <span className="text-sm">
            I understand this will delete all my data
          </span>
        </label>
        
        {error && (
          <p className="text-red-600 text-sm mb-4">{error}</p>
        )}
        
        <div className="flex gap-3">
          <button
            onClick={onCancel}
            className="flex-1 px-4 py-2 border border-gray-300 rounded-lg hover:bg-gray-50"
          >
            Cancel
          </button>
          <button
            onClick={handleConfirm}
            className="flex-1 px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700"
          >
            Delete & Import
          </button>
        </div>
      </div>
    </div>
  );
};

export default ImportModal;
```

### api.js Updates

```javascript
// Add to existing api.js

export const importAPI = {
  importBackup: async (file, mode, password) => {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('mode', mode);
    if (password) {
      formData.append('password', password);
    }

    const response = await axios.post('/api/import/backup', formData, {
      headers: {
        'Content-Type': 'multipart/form-data',
      },
    });

    return response.data;
  },
};
```

---

## Data Flow

### Merge Mode Flow

```
User Selects File
      ‚Üì
Frontend Validates (size, type)
      ‚Üì
User Clicks "Import Backup"
      ‚Üì
POST /api/import/backup
      ‚Üì
Backend: Authentication
      ‚Üì
Backend: Rate Limit Check
      ‚Üì
Backend: Parse JSON
      ‚Üì
Backend: Validate File Format (Layer 1-2)
      ‚Üì
Backend: Validate Content (Layer 3-5)
      ‚Üì
Backend: Detect Duplicates
      ‚Üì
Backend: Start Transaction
      ‚Üì
Backend: Import Recipes (skip duplicates)
      ‚Üì
Backend: Create ID Mapping
      ‚Üì
Backend: Import Collections (remap IDs)
      ‚Üì
Backend: Import Meal Plans (remap IDs)
      ‚Üì
Backend: Import Shopping Lists
      ‚Üì
Backend: Commit Transaction
      ‚Üì
Backend: Return Summary
      ‚Üì
Frontend: Display Success with Counts
```

### Replace Mode Flow

```
User Selects File
      ‚Üì
Frontend Validates (size, type)
      ‚Üì
User Selects "Replace Mode"
      ‚Üì
User Clicks "Import Backup"
      ‚Üì
Frontend: Show Confirmation Modal
      ‚Üì
User Enters Password & Confirms
      ‚Üì
POST /api/import/backup (with password)
      ‚Üì
Backend: Authentication
      ‚Üì
Backend: Rate Limit Check
      ‚Üì
Backend: Verify Password
      ‚Üì
Backend: Parse JSON
      ‚Üì
Backend: Validate File Format (Layer 1-2)
      ‚Üì
Backend: Validate Content (Layer 3-5)
      ‚Üì
Backend: Start Transaction
      ‚Üì
Backend: DELETE All User Data
      ‚Üì
Backend: Import Recipes (all)
      ‚Üì
Backend: Create ID Mapping
      ‚Üì
Backend: Import Collections (remap IDs)
      ‚Üì
Backend: Import Meal Plans (remap IDs)
      ‚Üì
Backend: Import Shopping Lists (all)
      ‚Üì
Backend: Commit Transaction
      ‚Üì
Backend: Return Summary
      ‚Üì
Frontend: Display Success
```

---

## Validation Pipeline

### 5-Layer Validation Strategy

```
Layer 1: File-Level Validation
‚îú‚îÄ‚îÄ File size check (< 50MB)
‚îú‚îÄ‚îÄ File type check (.json)
‚îî‚îÄ‚îÄ JSON parse validation

Layer 2: Schema Validation
‚îú‚îÄ‚îÄ Required fields present
‚îú‚îÄ‚îÄ Version compatibility (>= 2.0.0)
‚îú‚îÄ‚îÄ Data structure correct
‚îî‚îÄ‚îÄ User object valid

Layer 3: Content Validation
‚îú‚îÄ‚îÄ Recipe validation
‚îÇ   ‚îú‚îÄ‚îÄ Required fields (title, ingredients, instructions)
‚îÇ   ‚îú‚îÄ‚îÄ Field lengths
‚îÇ   ‚îú‚îÄ‚îÄ Array structures
‚îÇ   ‚îî‚îÄ‚îÄ Ingredient/instruction format
‚îú‚îÄ‚îÄ Collection validation
‚îÇ   ‚îú‚îÄ‚îÄ Name required
‚îÇ   ‚îî‚îÄ‚îÄ RecipeIds array
‚îú‚îÄ‚îÄ Meal plan validation
‚îÇ   ‚îú‚îÄ‚îÄ Date required
‚îÇ   ‚îú‚îÄ‚îÄ Meals array
‚îÇ   ‚îî‚îÄ‚îÄ Valid meal types
‚îî‚îÄ‚îÄ Shopping list validation
    ‚îú‚îÄ‚îÄ Name required
    ‚îî‚îÄ‚îÄ Items array

Layer 4: Reference Validation
‚îú‚îÄ‚îÄ Recipe IDs exist
‚îú‚îÄ‚îÄ Collection ‚Üí Recipe references
‚îî‚îÄ‚îÄ Meal Plan ‚Üí Recipe references

Layer 5: Security Validation
‚îú‚îÄ‚îÄ XSS prevention (strip script tags)
‚îú‚îÄ‚îÄ Field length limits
‚îú‚îÄ‚îÄ HTML entity sanitization
‚îî‚îÄ‚îÄ NoSQL injection prevention
```

---

## ID Remapping Strategy

### Why ID Remapping is Needed

Backup files contain MongoDB ObjectIds from the original database. When importing, we need to:
1. Create new MongoDB documents (which get new ObjectIds)
2. Maintain relationships between entities (collections ‚Üí recipes, meal plans ‚Üí recipes)
3. Handle missing references gracefully

### ID Mapping Implementation

```javascript
// Step 1: Process recipes first, build mapping
const idMapping = new Map();

for (const backupRecipe of backupData.recipes) {
  const oldId = backupRecipe._id;
  const newRecipe = await Recipe.create({...});
  const newId = newRecipe._id.toString();
  
  idMapping.set(oldId, newId); // Map old ‚Üí new
}

// Step 2: Use mapping for collections
for (const backupCollection of backupData.collections) {
  const remappedRecipeIds = backupCollection.recipeIds
    .map(oldId => idMapping.get(oldId))
    .filter(id => id !== undefined); // Remove missing refs
  
  await Collection.create({
    ...backupCollection,
    recipeIds: remappedRecipeIds
  });
}

// Step 3: Use mapping for meal plans
for (const backupMealPlan of backupData.mealPlans) {
  const remappedMeals = backupMealPlan.meals.map(meal => ({
    ...meal,
    recipes: meal.recipes
      .map(recipe => ({
        recipeId: idMapping.get(recipe.recipeId),
        ...recipe
      }))
      .filter(recipe => recipe.recipeId !== undefined)
  }));
  
  await MealPlan.create({
    ...backupMealPlan,
    meals: remappedMeals
  });
}
```

---

## Transaction Management

### MongoDB Transactions

```javascript
const session = await mongoose.startSession();

try {
  await session.startTransaction();
  
  // All database operations use session
  await Recipe.create([newRecipe], { session });
  await Collection.create([newCollection], { session });
  await MealPlan.create([newMealPlan], { session });
  await ShoppingList.create([newList], { session });
  
  // Commit if all succeed
  await session.commitTransaction();
  
} catch (error) {
  // Rollback if any fail
  await session.abortTransaction();
  throw error;
  
} finally {
  session.endSession();
}
```

### Transaction Benefits

1. **Atomicity**: All-or-nothing imports (no partial imports)
2. **Consistency**: Database stays consistent even on errors
3. **Isolation**: Concurrent operations don't interfere
4. **Durability**: Committed changes are permanent

---

## Error Handling

### Custom Error Class

```javascript
class ImportError extends Error {
  constructor(code, message, details = {}) {
    super(message);
    this.name = 'ImportError';
    this.code = code;
    this.details = details;
    this.statusCode = this.getStatusCode(code);
  }

  getStatusCode(code) {
    const statusCodes = {
      FILE_TOO_LARGE: 413,
      INVALID_FILE_TYPE: 400,
      INVALID_JSON: 400,
      MISSING_FIELD: 400,
      INCOMPATIBLE_VERSION: 400,
      INVALID_PASSWORD: 401,
      RATE_LIMIT_EXCEEDED: 429,
      IMPORT_ERROR: 500,
    };
    return statusCodes[code] || 400;
  }
}
```

---

## Security Design

### Rate Limiting Implementation

```javascript
const rateLimit = require('express-rate-limit');

const uploadLimiter = rateLimit({
  windowMs: 60 * 60 * 1000, // 1 hour
  max: 5, // 5 requests per hour per IP
  standardHeaders: true,
  legacyHeaders: false,
  handler: (req, res) => {
    res.status(429).json({
      success: false,
      error: 'Too many import attempts',
      details: {
        code: 'RATE_LIMIT_EXCEEDED',
        message: 'Maximum 5 imports per hour. Try again later.',
        retryAfter: Math.ceil(req.rateLimit.resetTime / 1000),
      },
    });
  },
});
```

### Input Sanitization

```javascript
const sanitizeMongoDB = (str) => {
  // Prevent NoSQL injection
  return str.replace(/[$.]/g, '');
};

const sanitizeHTML = (str) => {
  // Prevent XSS
  return str
    .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '')
    .replace(/javascript:/gi, '')
    .replace(/on\w+=/gi, '');
};
```

---

## Performance Considerations

### Optimization Strategies

1. **Batch Inserts**
   ```javascript
   // Instead of individual saves
   await Recipe.insertMany(recipes, { session });
   ```

2. **Index Usage**
   - Ensure indexes on `owner` field for fast lookups
   - Index on duplicate detection fields (title, name)

3. **Memory Management**
   - Stream large files instead of loading into memory
   - Process in chunks if > 1000 items

4. **Progress Reporting**
   - Update progress every 100 items
   - Use async processing for large imports

5. **Connection Pooling**
   - Reuse MongoDB connections
   - Configure pool size appropriately

---

**Design Phase Status**: Complete  
**Next Step**: Phase 4 - Implementation